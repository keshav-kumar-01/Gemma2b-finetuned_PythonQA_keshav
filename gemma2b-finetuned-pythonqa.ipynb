{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7e506fa",
   "metadata": {
    "papermill": {
     "duration": 0.009994,
     "end_time": "2024-02-25T11:36:33.489061",
     "exception": false,
     "start_time": "2024-02-25T11:36:33.479067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <mark>How to use Google Gemma</mark>\n",
    "\n",
    "Google has released Gemma 2B and 7B, a pair of open-source AI models that let developers use the research that went into its flagship Gemini more freely. While Gemini is a big closed AI model that directly competes with (and is nearly as powerful as) OpenAI’s ChatGPT, the lightweight Gemma will likely be suitable for smaller tasks like simple chatbots or summarizations.\n",
    "\n",
    "Here we will finetune to make a micmic model which will aid us in answering questions for python language, the main component is <mark>Dataset</mark>!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68991d34",
   "metadata": {
    "papermill": {
     "duration": 0.008414,
     "end_time": "2024-02-25T11:36:33.506573",
     "exception": false,
     "start_time": "2024-02-25T11:36:33.498159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Import numpy , pandas and OS Library, default code snippet given by Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c299f2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-25T11:36:33.525191Z",
     "iopub.status.busy": "2024-02-25T11:36:33.524881Z",
     "iopub.status.idle": "2024-02-25T11:36:34.327509Z",
     "shell.execute_reply": "2024-02-25T11:36:34.326628Z"
    },
    "papermill": {
     "duration": 0.814474,
     "end_time": "2024-02-25T11:36:34.329684",
     "exception": false,
     "start_time": "2024-02-25T11:36:33.515210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/parquetfile-python-25k/0000.parquet\n",
      "/kaggle/input/gemma/keras/gemma_2b_en/1/config.json\n",
      "/kaggle/input/gemma/keras/gemma_2b_en/1/tokenizer.json\n",
      "/kaggle/input/gemma/keras/gemma_2b_en/1/metadata.json\n",
      "/kaggle/input/gemma/keras/gemma_2b_en/1/model.weights.h5\n",
      "/kaggle/input/gemma/keras/gemma_2b_en/1/assets/tokenizer/vocabulary.spm\n",
      "/kaggle/input/gemma/keras/gemma_2b_en/2/config.json\n",
      "/kaggle/input/gemma/keras/gemma_2b_en/2/tokenizer.json\n",
      "/kaggle/input/gemma/keras/gemma_2b_en/2/metadata.json\n",
      "/kaggle/input/gemma/keras/gemma_2b_en/2/model.weights.h5\n",
      "/kaggle/input/gemma/keras/gemma_2b_en/2/assets/tokenizer/vocabulary.spm\n",
      "/kaggle/input/gemma/pytorch/2b/1/config.json\n",
      "/kaggle/input/gemma/pytorch/2b/1/gemma-2b.ckpt\n",
      "/kaggle/input/gemma/pytorch/2b/1/tokenizer.model\n",
      "/kaggle/input/data-assistants-with-gemma/submission_categories.txt\n",
      "/kaggle/input/data-assistants-with-gemma/submission_instructions.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaab254",
   "metadata": {
    "papermill": {
     "duration": 0.00861,
     "end_time": "2024-02-25T11:36:34.347365",
     "exception": false,
     "start_time": "2024-02-25T11:36:34.338755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Install Keras-NLP and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1968b57d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:36:34.366043Z",
     "iopub.status.busy": "2024-02-25T11:36:34.365656Z",
     "iopub.status.idle": "2024-02-25T11:37:02.861054Z",
     "shell.execute_reply": "2024-02-25T11:37:02.859935Z"
    },
    "papermill": {
     "duration": 28.507261,
     "end_time": "2024-02-25T11:37:02.863336",
     "exception": false,
     "start_time": "2024-02-25T11:36:34.356075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (21.3)\r\n",
      "Collecting packaging\r\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m838.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: packaging\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 21.3\r\n",
      "    Uninstalling packaging-21.3:\r\n",
      "      Successfully uninstalled packaging-21.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 23.8.0 requires cubinlinker, which is not installed.\r\n",
      "cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 23.8.0 requires ptxcompiler, which is not installed.\r\n",
      "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\r\n",
      "cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\r\n",
      "cuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\r\n",
      "dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\r\n",
      "dask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\r\n",
      "dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\r\n",
      "jupyterlab 4.0.11 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.8.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\r\n",
      "raft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed packaging-23.2\r\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (2.15.0)\r\n",
      "Collecting keras\r\n",
      "  Downloading keras-3.0.5-py3-none-any.whl.metadata (4.8 kB)\r\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras) (1.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras) (1.24.4)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras) (13.7.0)\r\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras) (0.0.7)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras) (3.10.0)\r\n",
      "Requirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras) (0.1.8)\r\n",
      "Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras) (0.2.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (2.17.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\r\n",
      "Downloading keras-3.0.5-py3-none-any.whl (1.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: keras\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 2.15.0\r\n",
      "    Uninstalling keras-2.15.0:\r\n",
      "      Successfully uninstalled keras-2.15.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed keras-3.0.5\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U packaging\n",
    "!pip install -U keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f44767e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:37:02.887302Z",
     "iopub.status.busy": "2024-02-25T11:37:02.886707Z",
     "iopub.status.idle": "2024-02-25T11:38:03.915407Z",
     "shell.execute_reply": "2024-02-25T11:38:03.914249Z"
    },
    "papermill": {
     "duration": 61.04373,
     "end_time": "2024-02-25T11:38:03.917934",
     "exception": false,
     "start_time": "2024-02-25T11:37:02.874204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\r\n",
      "Collecting tensorflow\r\n",
      "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.24.4)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.2)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\r\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\r\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow)\r\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\r\n",
      "Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: keras, tensorflow\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 3.0.5\r\n",
      "    Uninstalling keras-3.0.5:\r\n",
      "      Successfully uninstalled keras-3.0.5\r\n",
      "  Attempting uninstall: tensorflow\r\n",
      "    Found existing installation: tensorflow 2.15.0\r\n",
      "    Uninstalling tensorflow-2.15.0:\r\n",
      "      Successfully uninstalled tensorflow-2.15.0\r\n",
      "Successfully installed keras-2.15.0 tensorflow-2.15.0.post1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c90be88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:38:03.974836Z",
     "iopub.status.busy": "2024-02-25T11:38:03.974009Z",
     "iopub.status.idle": "2024-02-25T11:38:35.864907Z",
     "shell.execute_reply": "2024-02-25T11:38:35.863941Z"
    },
    "papermill": {
     "duration": 31.921399,
     "end_time": "2024-02-25T11:38:35.867330",
     "exception": false,
     "start_time": "2024-02-25T11:38:03.945931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow 2.15.0.post1 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -U keras-nlp\n",
    "!pip install -q -U keras>=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5a0534",
   "metadata": {
    "papermill": {
     "duration": 0.026625,
     "end_time": "2024-02-25T11:38:35.922521",
     "exception": false,
     "start_time": "2024-02-25T11:38:35.895896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### One can also try calling pretrained models from Hf, but will need latest transformers library for tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cb55913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:38:35.978015Z",
     "iopub.status.busy": "2024-02-25T11:38:35.977670Z",
     "iopub.status.idle": "2024-02-25T11:38:35.982017Z",
     "shell.execute_reply": "2024-02-25T11:38:35.981164Z"
    },
    "papermill": {
     "duration": 0.034601,
     "end_time": "2024-02-25T11:38:35.983979",
     "exception": false,
     "start_time": "2024-02-25T11:38:35.949378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  !pip install transformers==4.38.0\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\")\n",
    "\n",
    "# #Another notebook another day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec390e0",
   "metadata": {
    "papermill": {
     "duration": 0.027651,
     "end_time": "2024-02-25T11:38:36.039547",
     "exception": false,
     "start_time": "2024-02-25T11:38:36.011896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Go to hf and search for flytech/python-codes-25k and download parquet file and upload the dataset on kaggle and call it by pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d37943f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:38:36.107547Z",
     "iopub.status.busy": "2024-02-25T11:38:36.106861Z",
     "iopub.status.idle": "2024-02-25T11:38:36.593000Z",
     "shell.execute_reply": "2024-02-25T11:38:36.592166Z"
    },
    "papermill": {
     "duration": 0.527411,
     "end_time": "2024-02-25T11:38:36.595386",
     "exception": false,
     "start_time": "2024-02-25T11:38:36.067975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = pd.read_parquet(\"/kaggle/input/parquetfile-python-25k/0000.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af10a938",
   "metadata": {
    "papermill": {
     "duration": 0.026786,
     "end_time": "2024-02-25T11:38:36.649781",
     "exception": false,
     "start_time": "2024-02-25T11:38:36.622995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### We will pass parquet file by extracting Instruction and output column and will convert it into List + to save memory will delete the file variable later, also will only take rows from 0 to 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78976bf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:38:36.705219Z",
     "iopub.status.busy": "2024-02-25T11:38:36.704572Z",
     "iopub.status.idle": "2024-02-25T11:38:37.968151Z",
     "shell.execute_reply": "2024-02-25T11:38:37.967279Z"
    },
    "papermill": {
     "duration": 1.294041,
     "end_time": "2024-02-25T11:38:37.970648",
     "exception": false,
     "start_time": "2024-02-25T11:38:36.676607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=file.apply(lambda row:f\"Instruction:\\n{row.instruction}\\n\\nResponse:\\n{row.output}\",axis=1).values.tolist()[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "183ba1b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:38:38.034567Z",
     "iopub.status.busy": "2024-02-25T11:38:38.034210Z",
     "iopub.status.idle": "2024-02-25T11:38:38.038614Z",
     "shell.execute_reply": "2024-02-25T11:38:38.037639Z"
    },
    "papermill": {
     "duration": 0.038502,
     "end_time": "2024-02-25T11:38:38.040729",
     "exception": false,
     "start_time": "2024-02-25T11:38:38.002227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771d6ed",
   "metadata": {
    "papermill": {
     "duration": 0.03012,
     "end_time": "2024-02-25T11:38:38.101860",
     "exception": false,
     "start_time": "2024-02-25T11:38:38.071740",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### You can see by print statement what our \"data\" variable contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16ee576b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:38:38.163158Z",
     "iopub.status.busy": "2024-02-25T11:38:38.162863Z",
     "iopub.status.idle": "2024-02-25T11:38:38.167788Z",
     "shell.execute_reply": "2024-02-25T11:38:38.166858Z"
    },
    "papermill": {
     "duration": 0.037907,
     "end_time": "2024-02-25T11:38:38.170214",
     "exception": false,
     "start_time": "2024-02-25T11:38:38.132307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "Create a shopping list based on my inputs!\n",
      "\n",
      "Response:\n",
      "```python\n",
      "shopping_list = {}\n",
      "while True:\n",
      "    item = input('Enter an item or type 'done' to finish: ')\n",
      "    if item == 'done': break\n",
      "    quantity = input(f'Enter the quantity for {item}: ')\n",
      "    shopping_list[item] = quantity\n",
      "print(f'Your shopping list: {shopping_list}')\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75824651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:38:38.228023Z",
     "iopub.status.busy": "2024-02-25T11:38:38.227754Z",
     "iopub.status.idle": "2024-02-25T11:38:45.037721Z",
     "shell.execute_reply": "2024-02-25T11:38:45.036899Z"
    },
    "papermill": {
     "duration": 6.840059,
     "end_time": "2024-02-25T11:38:45.040105",
     "exception": false,
     "start_time": "2024-02-25T11:38:38.200046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-25 11:38:38.726895: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-25 11:38:38.726943: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-25 11:38:38.728505: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26e0198",
   "metadata": {
    "papermill": {
     "duration": 0.027486,
     "end_time": "2024-02-25T11:38:45.095068",
     "exception": false,
     "start_time": "2024-02-25T11:38:45.067582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Import necessary backend and to avoid memory fragmentation use the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e34102e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:38:45.153043Z",
     "iopub.status.busy": "2024-02-25T11:38:45.152445Z",
     "iopub.status.idle": "2024-02-25T11:38:45.157221Z",
     "shell.execute_reply": "2024-02-25T11:38:45.156342Z"
    },
    "papermill": {
     "duration": 0.036449,
     "end_time": "2024-02-25T11:38:45.159267",
     "exception": false,
     "start_time": "2024-02-25T11:38:45.122818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\" #or torch or tensorflow\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1ca464",
   "metadata": {
    "papermill": {
     "duration": 0.027847,
     "end_time": "2024-02-25T11:38:45.215343",
     "exception": false,
     "start_time": "2024-02-25T11:38:45.187496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Call the Gemma model by adding model from right hand side by add model button and add gemma 2billion 94.3 GB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a37d97c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:38:45.271876Z",
     "iopub.status.busy": "2024-02-25T11:38:45.270941Z",
     "iopub.status.idle": "2024-02-25T11:39:47.451112Z",
     "shell.execute_reply": "2024-02-25T11:39:47.450347Z"
    },
    "papermill": {
     "duration": 62.21053,
     "end_time": "2024-02-25T11:39:47.453443",
     "exception": false,
     "start_time": "2024-02-25T11:38:45.242913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb785ac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:39:47.511202Z",
     "iopub.status.busy": "2024-02-25T11:39:47.510592Z",
     "iopub.status.idle": "2024-02-25T11:39:47.544360Z",
     "shell.execute_reply": "2024-02-25T11:39:47.543501Z"
    },
    "papermill": {
     "duration": 0.064524,
     "end_time": "2024-02-25T11:39:47.546239",
     "exception": false,
     "start_time": "2024-02-25T11:39:47.481715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547a7d74",
   "metadata": {
    "papermill": {
     "duration": 0.028293,
     "end_time": "2024-02-25T11:39:47.603138",
     "exception": false,
     "start_time": "2024-02-25T11:39:47.574845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Use Lora to finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d05c85cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:39:47.662307Z",
     "iopub.status.busy": "2024-02-25T11:39:47.662051Z",
     "iopub.status.idle": "2024-02-25T11:39:47.799245Z",
     "shell.execute_reply": "2024-02-25T11:39:47.794428Z"
    },
    "papermill": {
     "duration": 0.169408,
     "end_time": "2024-02-25T11:39:47.801457",
     "exception": false,
     "start_time": "2024-02-25T11:39:47.632049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemma_lm.backbone.enable_lora(rank=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff5e8bb",
   "metadata": {
    "papermill": {
     "duration": 0.029338,
     "end_time": "2024-02-25T11:39:47.860370",
     "exception": false,
     "start_time": "2024-02-25T11:39:47.831032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### To save memory decrease the context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "473d90b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:39:47.923427Z",
     "iopub.status.busy": "2024-02-25T11:39:47.923085Z",
     "iopub.status.idle": "2024-02-25T11:39:47.927492Z",
     "shell.execute_reply": "2024-02-25T11:39:47.926550Z"
    },
    "papermill": {
     "duration": 0.040414,
     "end_time": "2024-02-25T11:39:47.929444",
     "exception": false,
     "start_time": "2024-02-25T11:39:47.889030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82826187",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:39:47.990209Z",
     "iopub.status.busy": "2024-02-25T11:39:47.989926Z",
     "iopub.status.idle": "2024-02-25T11:39:47.994848Z",
     "shell.execute_reply": "2024-02-25T11:39:47.993794Z"
    },
    "papermill": {
     "duration": 0.037871,
     "end_time": "2024-02-25T11:39:47.996870",
     "exception": false,
     "start_time": "2024-02-25T11:39:47.958999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Set GPU memory growth before any TensorFlow operations\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         for gpu in gpus:\n",
    "#             # Set memory growth before initializing the GPU\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "#         # Use only a fraction of the GPU memory\n",
    "#         tf.config.experimental.set_virtual_device_configuration(\n",
    "#             gpus[0],\n",
    "#             [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=0.8)]\n",
    "#         )\n",
    "\n",
    "#         logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#     except RuntimeError as e:\n",
    "#         # Memory growth must be set before GPUs have been initialized\n",
    "#         print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ed9fa5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:39:48.063553Z",
     "iopub.status.busy": "2024-02-25T11:39:48.062795Z",
     "iopub.status.idle": "2024-02-25T11:39:48.069965Z",
     "shell.execute_reply": "2024-02-25T11:39:48.069021Z"
    },
    "papermill": {
     "duration": 0.044738,
     "end_time": "2024-02-25T11:39:48.072090",
     "exception": false,
     "start_time": "2024-02-25T11:39:48.027352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if TPU is available\n",
    "if \"TPU_NAME\" in os.environ:\n",
    "    tpu_name = \"grpc://\" + os.environ[\"TPU_NAME\"]\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_name)\n",
    "    tf.config.experimental_connect_to_cluster(resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "else:\n",
    "    # Use default strategy for GPU/CPU\n",
    "    strategy = tf.distribute.get_strategy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4d2c16a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:39:48.139168Z",
     "iopub.status.busy": "2024-02-25T11:39:48.138891Z",
     "iopub.status.idle": "2024-02-25T11:39:48.143345Z",
     "shell.execute_reply": "2024-02-25T11:39:48.142719Z"
    },
    "papermill": {
     "duration": 0.04342,
     "end_time": "2024-02-25T11:39:48.145712",
     "exception": false,
     "start_time": "2024-02-25T11:39:48.102292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d01faeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:39:48.209479Z",
     "iopub.status.busy": "2024-02-25T11:39:48.209212Z",
     "iopub.status.idle": "2024-02-25T11:40:02.044951Z",
     "shell.execute_reply": "2024-02-25T11:40:02.043992Z"
    },
    "papermill": {
     "duration": 13.867793,
     "end_time": "2024-02-25T11:40:02.047371",
     "exception": false,
     "start_time": "2024-02-25T11:39:48.179578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0.post1)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.24.4)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.2)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\r\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\r\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow)\r\n",
      "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\r\n",
      "Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\r\n",
      "Installing collected packages: keras\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 3.0.5\r\n",
      "    Uninstalling keras-3.0.5:\r\n",
      "      Successfully uninstalled keras-3.0.5\r\n",
      "Successfully installed keras-2.15.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b637688",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:40:02.109431Z",
     "iopub.status.busy": "2024-02-25T11:40:02.109117Z",
     "iopub.status.idle": "2024-02-25T11:40:02.113249Z",
     "shell.execute_reply": "2024-02-25T11:40:02.112451Z"
    },
    "papermill": {
     "duration": 0.037098,
     "end_time": "2024-02-25T11:40:02.115118",
     "exception": false,
     "start_time": "2024-02-25T11:40:02.078020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.mixed_precision import mixed_precision\n",
    "\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_policy(policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97afe4fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:40:02.176381Z",
     "iopub.status.busy": "2024-02-25T11:40:02.176092Z",
     "iopub.status.idle": "2024-02-25T11:47:59.925641Z",
     "shell.execute_reply": "2024-02-25T11:47:59.924751Z"
    },
    "papermill": {
     "duration": 477.782548,
     "end_time": "2024-02-25T11:47:59.927591",
     "exception": false,
     "start_time": "2024-02-25T11:40:02.145043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1708861256.099834     106 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "W0000 00:00:1708861256.169796     106 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 424ms/step - loss: 1.0872 - sparse_categorical_accuracy: 0.6696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a7cf455b4f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit the input sequence length to 512 (to control memory usage).\n",
    "gemma_lm.preprocessor.sequence_length = 128\n",
    "# Use AdamW (a common optimizer for transformer models).\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=5e-6,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "# Exclude layernorm and bias terms from decay.\n",
    "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
    "\n",
    "gemma_lm.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=optimizer,\n",
    "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "gemma_lm.fit(data, epochs=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca181d81",
   "metadata": {
    "papermill": {
     "duration": 0.110606,
     "end_time": "2024-02-25T11:48:00.148124",
     "exception": false,
     "start_time": "2024-02-25T11:48:00.037518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Save the model, such that after inferencing, you can call the finetuned model and again finetune on more number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d59cfeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:48:00.374050Z",
     "iopub.status.busy": "2024-02-25T11:48:00.373642Z",
     "iopub.status.idle": "2024-02-25T11:48:55.424960Z",
     "shell.execute_reply": "2024-02-25T11:48:55.424081Z"
    },
    "papermill": {
     "duration": 55.16665,
     "end_time": "2024-02-25T11:48:55.427262",
     "exception": false,
     "start_time": "2024-02-25T11:48:00.260612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemma_lm.save(\"version_finetuned.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eac5ff5",
   "metadata": {
    "papermill": {
     "duration": 0.201121,
     "end_time": "2024-02-25T11:49:05.982043",
     "exception": false,
     "start_time": "2024-02-25T11:49:05.780922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### You can see it answers the question brilliantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "001bf8ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T11:49:06.217544Z",
     "iopub.status.busy": "2024-02-25T11:49:06.217175Z",
     "iopub.status.idle": "2024-02-25T11:49:30.520368Z",
     "shell.execute_reply": "2024-02-25T11:49:30.519241Z"
    },
    "papermill": {
     "duration": 24.41871,
     "end_time": "2024-02-25T11:49:30.522412",
     "exception": false,
     "start_time": "2024-02-25T11:49:06.103702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1708861768.982162      27 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "write a code for creating a list in python\n",
      "\n",
      "Response:\n",
      "import list\n",
      "my_list=[1,2,3,4]\n",
      "print(my_list[1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instruction=\"write a code for creating a list in python\"\n",
    "response=\"\"\n",
    "prompt = f\"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
    "print(gemma_lm.generate(prompt, max_length=128))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7669720,
     "sourceId": 64148,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 7769694,
     "datasetId": 4475204,
     "sourceId": 7672359,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 7769513,
     "datasetId": 4475088,
     "sourceId": 7672184,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 7769786,
     "datasetId": 4475281,
     "sourceId": 7672449,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 7764256,
     "modelInstanceId": 5305,
     "sourceId": 11216,
     "sourceType": "modelInstanceVersion"
    },
    {
     "databundleVersionId": 7771674,
     "modelInstanceId": 5171,
     "sourceId": 11371,
     "sourceType": "modelInstanceVersion"
    },
    {
     "databundleVersionId": 7715865,
     "modelInstanceId": 5171,
     "sourceId": 10260,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 783.674694,
   "end_time": "2024-02-25T11:49:34.183546",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-25T11:36:30.508852",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
